'use client';

import { useState, useCallback, useRef, useEffect } from 'react';
import { Send, Upload, Sparkles, HelpCircle, FileText, Image as ImageIcon, Copy, Check, Settings, AlertCircle, Loader2, XCircle } from 'lucide-react';
import { useDiagram } from '@/context/DiagramContext';
import { aiService } from '@/services/ai-service';
import { useAISettings } from '@/context/AISettingsContext';
import { parseDSL } from '@/lib/dsl-parser';
import { callGemini, parseJsonFromResponse } from '@/lib/gemini-api';
import AISettingsPanel from './AISettingsPanel';

interface Attachment {
    type: string;
    data: string; // base64
    name?: string;
}

interface Message {
    id: string;
    role: 'user' | 'assistant';
    content: string;
    timestamp: Date;
    attachments?: Attachment[];
}

export default function AIAssistantTab() {
    const { state, dispatch } = useDiagram();
    const { settings, isConfigured } = useAISettings();

    const [messages, setMessages] = useState<Message[]>([
        {
            id: '1',
            role: 'assistant',
            content: 'Hi! I can help you create Sankey diagrams from financial data. Try:\n\nâ€¢ Paste an image of a financial statement\nâ€¢ Type data like "Revenue [1000] Expenses"\nâ€¢ Ask me to modify colors or layout\nâ€¢ Request changes to your current diagram',
            timestamp: new Date(),
        },
    ]);
    const [input, setInput] = useState('');
    const [isProcessing, setIsProcessing] = useState(false);
    const [showSettings, setShowSettings] = useState(false);
    const [pendingFiles, setPendingFiles] = useState<Attachment[]>([]);
    const fileInputRef = useRef<HTMLInputElement>(null);

    // Convert messages to Gemini format for context
    const getConversationHistory = useCallback(() => {
        return messages.slice(1).map(msg => {
            const parts: any[] = [{ text: msg.content }];

            if (msg.attachments && msg.attachments.length > 0) {
                msg.attachments.forEach(att => {
                    parts.push({
                        inline_data: {
                            mime_type: att.type,
                            data: att.data.split(',')[1] // Remove base64 header
                        }
                    });
                });
            }

            return {
                role: msg.role === 'user' ? 'user' as const : 'model' as const,
                parts: parts
            };
        });
    }, [messages]);

    // Listen for AI actions from canvas (node context menu)
    useEffect(() => {
        const handleAINodeAction = (e: CustomEvent<{ nodeId: string; action: string; nodeName: string }>) => {
            const { nodeId, action, nodeName } = e.detail;

            let prompt = '';
            switch (action) {
                case 'breakdown':
                    prompt = `Suggest a breakdown for the node "${nodeName}" (ID: ${nodeId}). What sub-categories or components might this node contain?`;
                    break;
                case 'insights':
                    prompt = `Provide insights about the node "${nodeName}" (ID: ${nodeId}). What observations can you make based on its inflows, outflows, and value?`;
                    break;
                case 'optimize':
                    prompt = `Suggest optimizations for the node "${nodeName}" (ID: ${nodeId}). How could this value be improved or balanced?`;
                    break;
                default:
                    prompt = `Tell me about the node "${nodeName}" (ID: ${nodeId}).`;
            }

            // Set the input and trigger send
            setInput(prompt);
        };

        window.addEventListener('ai-node-action', handleAINodeAction as EventListener);
        return () => window.removeEventListener('ai-node-action', handleAINodeAction as EventListener);
    }, []);

    const handleSend = async () => {
        if ((!input.trim() && pendingFiles.length === 0) || isProcessing) return;

        const userMessage = input.trim();
        const attachmentsToSend = [...pendingFiles];

        // Clear inputs immediately
        setInput('');
        setPendingFiles([]);
        setIsProcessing(true);

        // Add user message to UI immediately
        setMessages(prev => [...prev, {
            id: Date.now().toString(),
            role: 'user',
            content: userMessage,
            attachments: attachmentsToSend,
            timestamp: new Date()
        }]);

        try {
            // Create settings override with attachments
            const settingsOverride = {
                ...settings,
                attachments: attachmentsToSend
            };

            const response = await aiService.sendMessage(userMessage || (attachmentsToSend.length > 0 ? "Analyze this image" : ""), state, settingsOverride);

            if (response.success) {
                setMessages(prev => [...prev, {
                    id: (Date.now() + 1).toString(),
                    role: 'assistant',
                    content: response.content,
                    timestamp: new Date()
                }]);

                // Check for JSON changes in the response
                const jsonMatch = response.content.match(/```json\n([\s\S]*?)\n```/);
                if (jsonMatch) {
                    try {
                        const changes = JSON.parse(jsonMatch[1]);

                        // Handle SETTINGS changes (theming)
                        if (changes.settings) {
                            dispatch({ type: 'UPDATE_SETTINGS', payload: changes.settings });
                            setMessages(prev => [...prev, {
                                id: (Date.now() + 2).toString(),
                                role: 'assistant',
                                content: 'ðŸŽ¨ Theme applied!',
                                timestamp: new Date()
                            }]);
                        }
                        // Handle SUGGESTIONS (node breakdown)
                        else if (changes.suggestions) {
                            const { nodeId, breakdown, insight } = changes.suggestions;
                            // For now, just show the insight. Later we can auto-apply breakdown.
                            const breakdownText = breakdown?.map((b: { name: string; value: number }) =>
                                `  â€¢ ${b.name}: ${b.value}`
                            ).join('\n') || '';

                            setMessages(prev => [...prev, {
                                id: (Date.now() + 2).toString(),
                                role: 'assistant',
                                content: `ðŸ’¡ **Suggestion for ${nodeId}:**\n${insight}\n\nProposed breakdown:\n${breakdownText}\n\nWould you like me to apply this breakdown?`,
                                timestamp: new Date()
                            }]);
                        }
                        // Handle DATA changes (nodes/flows)
                        else if (changes.nodes || changes.flows) {
                            const { applyAIChanges } = await import('@/lib/ai-utils');
                            const result = applyAIChanges(state, changes);

                            if (result.success && result.newState) {
                                dispatch({ type: 'SET_DATA', payload: result.newState.data });
                                setMessages(prev => [...prev, {
                                    id: (Date.now() + 2).toString(),
                                    role: 'assistant',
                                    content: 'âœ… Changes applied successfully!',
                                    timestamp: new Date()
                                }]);
                            } else {
                                const errorMsg = result.errors?.join('\n') || 'Failed to apply changes';
                                setMessages(prev => [...prev, {
                                    id: (Date.now() + 2).toString(),
                                    role: 'assistant',
                                    content: `âš ï¸ Could not apply changes:\n${errorMsg}`,
                                    timestamp: new Date()
                                }]);
                            }
                        }
                    } catch (e) {
                        console.error('Failed to parse/apply AI changes', e);
                    }
                }
            } else {
                setMessages(prev => [...prev, {
                    id: (Date.now() + 1).toString(),
                    role: 'assistant',
                    content: response.error || 'Sorry, I encountered an error processing your request.',
                    timestamp: new Date()
                }]);
            }
        } catch (error) {
            console.error('AI Service Error:', error);
            setMessages(prev => [...prev, {
                id: (Date.now() + 1).toString(),
                role: 'assistant',
                content: 'Sorry, something went wrong.',
                timestamp: new Date()
            }]);
        } finally {
            setIsProcessing(false);
        }
    };

    const handleFileUpload = useCallback((e: React.ChangeEvent<HTMLInputElement>) => {
        const file = e.target.files?.[0];
        if (!file) return;

        const isImage = file.type.startsWith('image/');
        const isPDF = file.type === 'application/pdf';

        if (!isImage && !isPDF) {
            alert('Please upload an image (PNG, JPG) or PDF file.');
            return;
        }

        const reader = new FileReader();
        reader.onload = async (e) => {
            const base64Data = e.target?.result as string;
            setPendingFiles(prev => [...prev, {
                type: file.type,
                data: base64Data,
                name: file.name
            }]);
        };
        reader.readAsDataURL(file);

        if (fileInputRef.current) {
            fileInputRef.current.value = '';
        }
    }, []);

    const handlePaste = useCallback((e: React.ClipboardEvent) => {
        const items = e.clipboardData.items;
        for (const item of items) {
            if (item.type.startsWith('image/')) {
                e.preventDefault();
                const file = item.getAsFile();
                if (file) {
                    const reader = new FileReader();
                    reader.onload = (e) => {
                        const base64Data = e.target?.result as string;
                        setPendingFiles(prev => [...prev, {
                            type: file.type,
                            data: base64Data,
                            name: "Pasted Image"
                        }]);
                    };
                    reader.readAsDataURL(file);
                }
                break;
            }
        }
    }, []);

    return (
        <div className="flex flex-col h-full">
            {/* Header with Settings */}
            <div className="flex items-center justify-between px-4 py-2 border-b border-[var(--border)] bg-gradient-to-r from-purple-50 to-blue-50  ">
                <div className="flex items-center gap-2">
                    <Sparkles className="w-4 h-4 text-purple-500" />
                    <span className="text-sm font-medium text-[var(--primary-text)]">AI Assistant</span>
                    {!isConfigured && (
                        <span className="px-2 py-0.5 bg-amber-100 text-amber-700 text-xs rounded-full">
                            Not Configured
                        </span>
                    )}
                </div>
                <button
                    onClick={() => setShowSettings(true)}
                    className="p-2 text-[var(--secondary-text)] hover:text-[var(--primary-text)] hover:bg-[var(--hover-bg)] rounded-lg transition-colors"
                    title="AI Settings"
                >
                    <Settings className="w-4 h-4" />
                </button>
            </div>

            {/* API Key Warning */}
            {!isConfigured && (
                <div className="mx-4 mt-3 px-3 py-2 bg-amber-50  border border-amber-200  rounded-lg">
                    <div className="flex items-start gap-2">
                        <AlertCircle className="w-4 h-4 text-amber-500 flex-shrink-0 mt-0.5" />
                        <div className="text-xs text-amber-700 ">
                            <span className="font-medium">API key required</span> for AI features.{' '}
                            <button
                                onClick={() => setShowSettings(true)}
                                className="text-amber-800  underline hover:no-underline"
                            >
                                Configure now â†’
                            </button>
                        </div>
                    </div>
                </div>
            )}

            {/* Messages */}
            <div className="flex-1 overflow-y-auto p-4 space-y-4">
                {messages.map((msg) => (
                    <div
                        key={msg.id}
                        className={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}
                    >
                        <div className={`flex flex-col gap-2 max-w-[85%] ${msg.role === 'user' ? 'items-end' : 'items-start'}`}>
                            {msg.attachments && msg.attachments.length > 0 && (
                                <div className="flex flex-wrap gap-2 mb-1 justify-end">
                                    {msg.attachments.map((att, i) => (
                                        <div key={i} className="relative group">
                                            {att.type.startsWith('image/') ? (
                                                <img
                                                    src={att.data}
                                                    alt="Attachment"
                                                    className="h-20 w-auto rounded-lg border border-gray-200 shadow-sm"
                                                />
                                            ) : (
                                                <div className="flex items-center gap-2 p-2 bg-gray-100 rounded-lg border border-gray-200">
                                                    <FileText className="w-4 h-4 text-gray-500" />
                                                    <span className="text-xs text-gray-600 truncate max-w-[100px]">{att.name || 'File'}</span>
                                                </div>
                                            )}
                                        </div>
                                    ))}
                                </div>
                            )}
                            <div
                                className={`rounded-lg px-4 py-2 text-sm whitespace-pre-wrap w-full ${msg.role === 'user'
                                    ? 'bg-gradient-to-r from-purple-500 to-blue-500 text-white'
                                    : 'bg-[var(--background)] text-[var(--primary-text)]'
                                    }`}
                            >
                                {msg.role === 'assistant' && (
                                    <div className="flex items-center gap-1 text-xs text-gray-500 mb-1">
                                        <Sparkles className="w-3 h-3" />
                                        AI Assistant
                                    </div>
                                )}
                                {msg.content}
                            </div>
                        </div>
                    </div>
                ))}

                {isProcessing && (
                    <div className="flex justify-start">
                        <div className="bg-[var(--background)] rounded-lg px-4 py-3 text-sm">
                            <Loader2 className="w-4 h-4 animate-spin text-purple-500" />
                        </div>
                    </div>
                )}
            </div>

            {/* Input Area */}
            <div className="border-t border-[var(--border)] p-4 bg-[var(--card-bg)]">
                {/* Pending Files Staging Area */}
                {pendingFiles.length > 0 && (
                    <div className="flex gap-2 mb-3 overflow-x-auto py-2">
                        {pendingFiles.map((file, index) => (
                            <div key={index} className="relative group shrink-0">
                                {file.type.startsWith('image/') ? (
                                    <img
                                        src={file.data}
                                        alt="Preview"
                                        className="h-16 w-auto rounded-md border border-gray-200"
                                    />
                                ) : (
                                    <div className="h-16 w-16 flex items-center justify-center bg-gray-100 rounded-md border border-gray-200">
                                        <FileText className="w-6 h-6 text-gray-400" />
                                    </div>
                                )}
                                <button
                                    onClick={() => setPendingFiles(prev => prev.filter((_, i) => i !== index))}
                                    className="absolute -top-1.5 -right-1.5 p-0.5 bg-red-500 text-white rounded-full opacity-0 group-hover:opacity-100 transition-opacity"
                                >
                                    <XCircle className="w-4 h-4" />
                                </button>
                            </div>
                        ))}
                    </div>
                )}

                <div className="flex gap-2">
                    <input
                        type="file"
                        ref={fileInputRef}
                        onChange={handleFileUpload}
                        accept="image/*,.pdf"
                        className="hidden"
                    />

                    <button
                        onClick={() => fileInputRef.current?.click()}
                        className="p-2 text-[var(--secondary-text)] hover:text-[var(--primary-text)] hover:bg-[var(--hover-bg)] rounded-lg transition-colors"
                        title="Upload image or PDF"
                    >
                        <ImageIcon className="w-5 h-5" />
                    </button>

                    <input
                        type="text"
                        value={input}
                        onChange={(e) => setInput(e.target.value)}
                        onKeyDown={(e) => e.key === 'Enter' && !e.shiftKey && handleSend()}
                        onPaste={handlePaste}
                        placeholder={isConfigured ? "Ask me anything about your diagram..." : "Type data or configure API key..."}
                        className="flex-1 px-3 py-2 border border-[var(--border)] rounded-lg text-sm focus:outline-none focus:ring-2 focus:ring-purple-500 bg-[var(--card-bg)] text-[var(--primary-text)]"
                        disabled={isProcessing}
                    />

                    <button
                        onClick={handleSend}
                        disabled={(!input.trim() && pendingFiles.length === 0) || isProcessing}
                        className="p-2 bg-gradient-to-r from-purple-500 to-blue-500 text-white rounded-lg hover:from-purple-600 hover:to-blue-600 disabled:opacity-50 disabled:cursor-not-allowed transition-all"
                    >
                        <Send className="w-5 h-5" />
                    </button>
                </div>

                <p className="mt-2 text-xs text-[var(--secondary-text)] text-center">
                    {isConfigured ? 'AI-powered â€¢ Type or paste data' : 'Paste images or type: Source [Amount] Target'}
                </p>
            </div>

            {/* Settings Modal */}
            <AISettingsPanel isOpen={showSettings} onClose={() => setShowSettings(false)} />
        </div>
    );
}

